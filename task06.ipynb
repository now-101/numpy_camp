{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 模型融合\n",
    "\n",
    "## 接任务五内容：\n",
    "使用五折交叉验证法，GridSearch来寻找模型的最优参数¶\n",
    "\n",
    "ref:https://github.com/toAlgorithm/machineLearning/blob/master/data_mining/task5/task5.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入与切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('./dataset/task2_proc.csv')\n",
    "\n",
    "labels = dataset['status']\n",
    "features = dataset.drop(['status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_state = 2018\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.3,\n",
    "                                                   random_state=random_state)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "x_train_scale = scaler.fit_transform(x_train)\n",
    "x_test_scale = scaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用逻辑回归运行五折交叉验证，网格搜索来获取最优参数\n",
    "C为正则化系数λ的倒数，必须为整数，默认为1，值越小，代表正则化越强。一般来说只需要调节这个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'C': 0.05} with a score of 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_lr = GridSearchCV(LogisticRegression(), \n",
    "                       param_grid={'C': [0.01, 0.05, 0.1, 0.2, 0.5, 1, 10]},                         \n",
    "                       cv=5  # \n",
    "                      )\n",
    "grid_lr.fit(x_train_scale, y_train)\n",
    "print('Best parameters:{} with a score of {:.3f}'.format(grid_lr.best_params_, grid_lr.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用SVM运行五折交叉验证，网格搜索获取最后参数\n",
    "惩罚系数C，核函数参数gamma，可以调节这两个参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'C': 0.05} with a score of 0.797\n"
     ]
    }
   ],
   "source": [
    "grid_svm = GridSearchCV(SVC(probability=True),\n",
    "                       param_grid={'C': [0.1, 0.5, 1, 10, 20],\n",
    "                                   'gamma': [1, 0,5, 0.1, 0.01]})\n",
    "grid_svm.fit(x_train_scale, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'C': 1, 'gamma': 0.01} with a score of 0.788\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:{} with a score of {:.3f}'.format(grid_svm.best_params_, grid_svm.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用决策树运行五折交叉验证，网格搜索获取最后参数\n",
    "决策树的模型一般只需要调节最大深度即可\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'max_depth': 5} with a score of 0.763\n"
     ]
    }
   ],
   "source": [
    "grid_dt = GridSearchCV(DecisionTreeClassifier(),\n",
    "                      param_grid={'max_depth':[i for i in range(1, 10)]},\n",
    "                      cv=5)\n",
    "grid_dt.fit(x_train_scale, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters:{} with a score of {:.3f}'.format(grid_dt.best_params_, grid_dt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用随机森林运行五折交叉验证，网格搜索获取最后参数\n",
    "[随机森林各参数含义以及调参实例传送门](https://www.cnblogs.com/pinard/p/6160412.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里先采用了分四步的搜索方法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'n_estimators': 60} with a score of 0.786\n"
     ]
    }
   ],
   "source": [
    "# 1、先对步长和迭代次数进行调参\n",
    "param_test_1 = {'n_estimators': range(10, 71, 10)}\n",
    "gs_rf_step_1 = GridSearchCV(estimator=RandomForestClassifier(min_samples_split=100,\n",
    "                                                           min_samples_leaf=20,\n",
    "                                                           max_depth=8,\n",
    "                                                           max_features='sqrt',\n",
    "                                                           random_state=10),\n",
    "                          param_grid=param_test_1,\n",
    "                          scoring='roc_auc',\n",
    "                          cv=5)\n",
    "gs_rf_step_1.fit(x_train_scale, y_train)\n",
    "print('Best parameters:{} with a score of {:.3f}'.format(gs_rf_step_1.best_params_, gs_rf_step_1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'max_depth': 11, 'min_samples_split': 10} with a score of 0.788\n"
     ]
    }
   ],
   "source": [
    "# 2、对其弱分类器决策树进行调参\n",
    "param_test_2 = {'max_depth':range(3, 14, 2), 'min_samples_split': range(10, 201, 10)}\n",
    "gs_rf_step_2 = GridSearchCV(estimator=RandomForestClassifier(n_estimators=60,\n",
    "                                                            min_samples_leaf=20,\n",
    "                                                            max_features='sqrt',\n",
    "                                                            oob_score=True, \n",
    "                                                            random_state=10),\n",
    "                           param_grid=param_test_2,\n",
    "                           scoring='roc_auc',\n",
    "                           iid=False,\n",
    "                           cv=5)\n",
    "gs_rf_step_2.fit(x_train_scale, y_train)\n",
    "\n",
    "print('Best parameters:{} with a score of {:.3f}'.format(gs_rf_step_2.best_params_, gs_rf_step_2.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'min_samples_leaf': 20} with a score of 0.787\n"
     ]
    }
   ],
   "source": [
    "# 3、对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参\n",
    "param_test_3 = {'min_samples_leaf':range(10, 60, 10)}\n",
    "gs_rf_step_3 = GridSearchCV(estimator=RandomForestClassifier(n_estimators=60, \n",
    "                                                            max_depth=9,\n",
    "                                                            min_samples_split=110,\n",
    "                                                            max_features='sqrt',\n",
    "                                                            oob_score=True,\n",
    "                                                            random_state=10),\n",
    "                           param_grid=param_test_3,\n",
    "                           scoring='roc_auc', \n",
    "                           iid=False,\n",
    "                           cv=5)\n",
    "gs_rf_step_3.fit(x_train_scale, y_train)\n",
    "print('Best parameters:{} with a score of {:.3f}'.format(gs_rf_step_3.best_params_, gs_rf_step_3.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'max_features': 11} with a score of 0.787\n"
     ]
    }
   ],
   "source": [
    "# 4、最后我们再对最大特征数max_features做调参:\n",
    "param_test_4 = {'max_features':(3,11,2)}\n",
    "gs_rf_step_4 = GridSearchCV(estimator=RandomForestClassifier(n_estimators=60,\n",
    "                                                            max_depth=9,\n",
    "                                                            min_samples_leaf=20,\n",
    "                                                            min_samples_split=10,\n",
    "                                                            oob_score=True,\n",
    "                                                            random_state=10),\n",
    "                           param_grid=param_test_4,\n",
    "                           scoring='roc_auc',\n",
    "                           iid=False,\n",
    "                           cv=5)\n",
    "gs_rf_step_4.fit(x_train_scale, y_train)\n",
    "print('Best parameters:{} with a score of {:.3f}'.format(gs_rf_step_4.best_params_, gs_rf_step_4.best_score_))\n",
    "                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型融合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Lr_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bdfeb370b6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 模型融合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLr_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_cv\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mrf_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_cv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mS_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Initialize 2-nd level model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Lr_cv' is not defined"
     ]
    }
   ],
   "source": [
    "# 模型融合\n",
    "model_list = [Lr_cv, svc_cv, dt_cv,  rf_cv, xgb_cv]\n",
    "S_train, S_test = stacking(model_list, x_train, y_train,  x_test, regression=False, n_folds=5)\n",
    "\n",
    "# # Initialize 2-nd level model\n",
    "model = GradientBoostingClassifier(learning_rate = 0.1, n_estimators = 100, max_depth = 3)\n",
    "\n",
    "# # Fit 2-nd level model\n",
    "model_s = model.fit(S_train, y_train)\n",
    "\n",
    "# # Predict\n",
    "y_pred = model_s.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "# print('Final prediction score: [%.8f]' % metrics.accuracy_score(y_test, y_pred))\n",
    "acc_score_test = metrics.accuracy_score(y_pred, y_test)\n",
    "precision_score_test = metrics.precision_score(y_pred, y_test)\n",
    "recall_score_test = metrics.recall_score(y_pred, y_test)\n",
    "f1_score_test = metrics.f1_score(y_pred, y_test)\n",
    "roc_auc_score_test = metrics.roc_auc_score(y_pred, y_test)\n",
    "\n",
    "print('Final 测试集准确率：{}\\n'.format(acc_score_test))\n",
    "print('Final 测试集精确率：{}\\n'.format(precision_score_test))\n",
    "print('Final 测试集召回率：{}\\n'.format(recall_score_test))\n",
    "print('Final 测试集f1评分：{}\\n'.format(f1_score_test))\n",
    "print('Final 测试集AUC值：{}\\n'.format(roc_auc_score_test))\n",
    "        \n",
    "        \n",
    "\n",
    "# model_est(model_dict_s, x_train, x_test, y_train, y_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7aeab587cf94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m sclf = StackingClassifier(classifiers=[Lr_cv, dt_cv, rf_cv, xgb_cv, svc_cv],\n\u001b[1;32m      3\u001b[0m                           meta_classifier=xgb_cv)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_dict_mlxtend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'融合模型'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msclf\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_est\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict_mlxtend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "sclf = StackingClassifier(classifiers=[Lr_cv, dt_cv, rf_cv, xgb_cv, svc_cv],\n",
    "                          meta_classifier=xgb_cv)\n",
    "model_dict_mlxtend = {'融合模型':sclf}\n",
    "model_est(model_dict_mlxtend, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
